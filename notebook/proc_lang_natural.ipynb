{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Textuais: classificação e exploração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyLldsoOUCqD",
    "outputId": "c27ec508-d98a-4add-d7c1-f50f8a869515"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resenha = pd.read_csv(\"dados/imdb-reviews-pt-br.csv\")\n",
    "resenha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYBl3ve8UCqp",
    "outputId": "e8bd5ae8-9e1a-4321-86c4-ed149353d53f"
   },
   "outputs": [],
   "source": [
    "print(resenha.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4vhDB2IUCrF"
   },
   "outputs": [],
   "source": [
    "classificacao = resenha[\"sentiment\"].replace([\"neg\", \"pos\"], [0,1])\n",
    "resenha[\"classificacao\"] = classificacao\n",
    "resenha.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words: criando representações da linguagem humana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bDsMPtaUCsF",
    "outputId": "6fba557d-455b-4b4a-b61a-d4e757cd970b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
    "exemplo_texto = ['texto maluco TExto', 'muito maluco mais ou menos bom', 'texto muito bom', 'texto muito ruim']\n",
    "bag_of_words = vetorizar.fit_transform(exemplo_texto)\n",
    "print(vetorizar.get_feature_names())\n",
    "print(bag_of_words.shape)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificar_texto(texto, coluna_texto, coluna_classificacao):\n",
    "    vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
    "    bag_of_words = vetorizar.fit_transform(texto[coluna_texto])\n",
    "\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words,\n",
    "                                                              texto[coluna_classificacao],\n",
    "                                                              random_state = 42)\n",
    "\n",
    "    regressao_logistica = LogisticRegression(solver = \"lbfgs\")\n",
    "    regressao_logistica.fit(treino, classe_treino)\n",
    "\n",
    "    return regressao_logistica.score(teste, classe_teste)\n",
    "\n",
    "\n",
    "res = classificar_texto(resenha, \"text_pt\", \"classificacao\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando os dados com WordCloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpfg-qTsUCsM"
   },
   "outputs": [],
   "source": [
    "# conda install -c conda-forge wordcloud\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "exemplo_texto = ['texto maluco TExto', 'muito maluco mais ou menos bom', 'texto muito bom', 'texto muito ruim']\n",
    "todas_palavras = ' '.join([texto for texto in exemplo_texto])\n",
    "# todas_palavras = ' '.join([texto for texto in resenha.text_pt])\n",
    "\n",
    "nuvem_palavras = WordCloud(width= 800, height= 500,\n",
    "                          max_font_size = 110,\n",
    "                          collocations = False).generate(todas_palavras)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(nuvem_palavras, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60Mg6boWUCsW"
   },
   "outputs": [],
   "source": [
    "def nuvem_palavras_neg(texto, coluna_texto):\n",
    "    texto_negativo = texto.query(\"sentiment == 'neg'\")\n",
    "    todas_palavras = ' '.join([texto for texto in texto_negativo[coluna_texto]])\n",
    "\n",
    "    nuvem_palavras = WordCloud(width= 800, height= 500,\n",
    "                              max_font_size = 110,\n",
    "                              collocations = False).generate(todas_palavras)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(nuvem_palavras, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "nuvem_palavras_neg(resenha, \"text_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oIvSpMvUCsc"
   },
   "outputs": [],
   "source": [
    "def nuvem_palavras_pos(texto, coluna_texto):\n",
    "    texto_positivo = texto.query(\"sentiment == 'pos'\")\n",
    "    todas_palavras = ' '.join([texto for texto in texto_positivo[coluna_texto]])\n",
    "\n",
    "    nuvem_palavras = WordCloud(width= 800, height= 500,\n",
    "                              max_font_size = 110,\n",
    "                              collocations = False).generate(todas_palavras)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(nuvem_palavras, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "nuvem_palavras_pos(resenha, \"text_pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenização e a bliblioteca NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CbLzrQoUCsr",
    "outputId": "d43c959a-8a14-4273-8c89-8b189d900bbf"
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "frase = [\"um filme bom\", \"um filme ruim\"]\n",
    "frequencia = nltk.FreqDist(frase)\n",
    "frequencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cG1v2w9RUCsx",
    "outputId": "4030294b-c9c4-4f27-d6ca-1f47b7b26b17"
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "frase = \"Bem vindo ao mundo do PLN!\"\n",
    "\n",
    "token_espaco = tokenize.WhitespaceTokenizer()\n",
    "token_frase = token_espaco.tokenize(frase)\n",
    "print(token_frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlGZxxXTUCs2"
   },
   "outputs": [],
   "source": [
    "token_frase = token_espaco.tokenize(todas_palavras)\n",
    "frequencia = nltk.FreqDist(token_frase)\n",
    "df_frequencia = pd.DataFrame({\"Palavra\": list(frequencia.keys()),\n",
    "                                   \"Frequência\": list(frequencia.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSH2IZmbUCs5",
    "outputId": "b474a4ba-395c-452d-f591-925c3c81f562"
   },
   "outputs": [],
   "source": [
    "df_frequencia.nlargest(columns = \"Frequência\", n = 10)"
   ]
  },
  {
   "source": [
    "## Uma nova visualização e os stop words."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def pareto(texto, coluna_texto, quantidade):\n",
    "    todas_palavras = ' '.join([texto for texto in texto[coluna_texto]])\n",
    "    token_frase = token_espaco.tokenize(todas_palavras)\n",
    "    frequencia = nltk.FreqDist(token_frase)\n",
    "    df_frequencia = pd.DataFrame({\"Palavra\": list(frequencia.keys()),\n",
    "                                   \"Frequência\": list(frequencia.values())})\n",
    "    df_frequencia = df_frequencia.nlargest(columns = \"Frequência\", n = quantidade)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = sns.barplot(data = df_frequencia, x = \"Palavra\", y = \"Frequência\", color = 'gray')\n",
    "    ax.set(ylabel = \"Contagem\")\n",
    "    plt.show()\n",
    "\n",
    "pareto(resenha, \"text_pt\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('all') # --> muito demorado\n",
    "# nltk.download('portuguese') # --> mais rapido\n",
    "\n",
    "palavras_irrelevantes = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "\n",
    "frase_processada = list()\n",
    "for opiniao in resenha.text_pt:\n",
    "    nova_frase = list()\n",
    "    palavras_texto = token_espaco.tokenize(opiniao)\n",
    "    for palavra in palavras_texto:\n",
    "        if palavra not in palavras_irrelevantes:\n",
    "            nova_frase.append(palavra)\n",
    "    frase_processada.append(' '.join(nova_frase))\n",
    "    \n",
    "resenha[\"tratamento_1\"] = frase_processada\n",
    "# resenha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificar_texto(resenha, \"tratamento_1\", \"classificacao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto(resenha,\"tratamento_1\", 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PLN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "a707b6ce8c685eb936424fcc3009d4b4b7a52543c4db09380a3fc49186ceb509"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}